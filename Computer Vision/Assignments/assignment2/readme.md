# Assignment 2 - Digital Image (Pre)Processing.

Make sure you have python installed on your machine

The python version which was used in development is Python 3.9

Make sure you have installed packages that are required for this project

### To run the code from the terminal, change the directory to the root of the project and run:

`python3 main.py`

`main.py` will import required scripts for task 1, 2 and 3 and run them

## Folder structure

[Assets](assets) folder contains noisy photos that we work on

[Generated](generated) folder contains images that are generated by the code. The folder also contains sub-folders for the tasks. If you run the code the files will simply be overwritten.


## Code structure

Code is divided by tasks, so we have:
`task1.py`, `task2.py`, `task3.py` and we also have `main.py` which is the entry for the code and gathers all tasks together.
To differentiate between tasks we can comment and uncomment the function calls in `main.py` file.

## Code Comments

### Task 1:

The entry point for task 1 is `task1` function, it makes function calls to subtasks.

Firstly I apply morphology, all spatial filters and frequency filters and show and save the results of it.

After that I have created a combination of morphology with median blur to get rid of salt and pepper. It copes with the problem pretty well, but with the cost of unrecognizable letters in chemical structure. `gettingRidOfSaltAndPepper` is the name of function

There is one more call to what in my opinion is the best performing combination and fucntion is called `bestPerformant`. It uses bilateral filter with combination of morphology. Although there are still some salt and pepper left in the photo, lines are reconstructed, letters are still recognizable and salt and pepper is considerably decreased.

Lastly, last function call for task 1 is adding noise and then restoring the image from the first assignment. The best way that I have found that works on my photo to restore the image after adding the Gaussian noise to the photo is applying median blur. In the code I have tried 3 kernels: 9, 15 and 25. The bigger the size of the kernel less noise the photo had, but more blurry it was. 

### Task 2:

Similarly to the first task, the entry point for the second task is `task2` function.

There I create an array of images for speckle noisy images and iterate over them applying medianBlur of different kernel size (5,7,9) and in my opinion the best performing was 7, it was the most clear and had the least amount of noise, after that I apply crimmins speckle removal with again different kernel size (5,7,9) and this time it is harder to say which one is the best performing, it was depending on the photo. 

Generally speaking, although medianBlur is best known for removing salt and pepper noise, it is also performed well for removing speckle noise. Criminals speckle removal is performing very well for removing speckle noise.

### Task 3:

Task 3 contains only one function which is called from `main.py` and it is called `task3`. In this task I use `pydicom` library to read MRI images and the metadata of it, and `imageio` to create the gif from the given MRI images.

The way it works is we are giving a folder name from test dataset by default it is set to `'00001'` and we have an array of subfolders which we iterate over and read the images and metadata. After that we create a gif from the images and save it in the `generated\task3` folder with the creation of the folder according to the given folder name.

Finally, the metadata of the first image in the folder is printed to the console.